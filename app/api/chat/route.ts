import {
  streamText,
  UIMessage,
  convertToModelMessages,
  stepCountIs,
  createUIMessageStream,
  createUIMessageStreamResponse,
  type CoreSystemMessage,
} from "ai";

import { MODEL } from "@/config";
import {
  IDENTITY_PROMPT,
  TOOL_CALLING_PROMPT,
  TOOL_CALLING_OPTIONS,
  TOOL_CALLING_BEHAVIOR_RULES,
  TOOL_CALLING_FOLLOWUP_RULES_YES,
  TOOL_CALLING_FOLLOWUP_RULES_NO,
  TOOL_CALLING_OTHER_RULES,
  TONE_STYLE_PROMPT,
  GUARDRAILS_PROMPT,
  CITATIONS_PROMPT,
} from "@/prompts";

import { isContentFlagged } from "@/lib/moderation";
import { webSearch } from "./tools/web-search";
import { vectorDatabaseSearch } from "./tools/search-vector-database";

export const maxDuration = 30;

export async function POST(req: Request) {
  const { messages }: { messages: UIMessage[] } = await req.json();

  // --------------------------------------------------
  // MODERATION CHECK (unchanged)
  // --------------------------------------------------
  const latestUserMessage = messages.filter((m) => m.role === "user").pop();

  if (latestUserMessage) {
    const textParts = latestUserMessage.parts
      .filter((part) => part.type === "text")
      .map((part) => ("text" in part ? part.text : ""))
      .join("");

    if (textParts) {
      const moderationResult = await isContentFlagged(textParts);

      if (moderationResult.flagged) {
        const stream = createUIMessageStream({
          execute({ writer }) {
            const id = "moderation-denial-text";

            writer.write({ type: "start" });
            writer.write({ type: "text-start", id });

            writer.write({
              type: "text-delta",
              id,
              delta:
                moderationResult.denialMessage ||
                "Your message violates our guidelines. I can't answer that.",
            });

            writer.write({ type: "text-end", id });
            writer.write({ type: "finish" });
          },
        });

        return createUIMessageStreamResponse({ stream });
      }
    }
  }

  // --------------------------------------------------
  // BASE SYSTEM PROMPTS (your original ones)
  // --------------------------------------------------

  const systemMessages: CoreSystemMessage[] = [
    { role: "system", content: IDENTITY_PROMPT },
    { role: "system", content: TOOL_CALLING_PROMPT },
    { role: "system", content: TOOL_CALLING_OPTIONS },
    { role: "system", content: TOOL_CALLING_BEHAVIOR_RULES },
    { role: "system", content: TOOL_CALLING_FOLLOWUP_RULES_YES },
    { role: "system", content: TOOL_CALLING_FOLLOWUP_RULES_NO },
    { role: "system", content: TOOL_CALLING_OTHER_RULES },
    { role: "system", content: TONE_STYLE_PROMPT },
    { role: "system", content: GUARDRAILS_PROMPT },
    { role: "system", content: CITATIONS_PROMPT },
  ];

  // --------------------------------------------------
  // PREPARE CHAT HISTORY FOR THE MODEL
  // --------------------------------------------------

  const modelMessages = convertToModelMessages(messages);

  // Detect if latest user message is a compare request
  const latestText =
    latestUserMessage &&
    latestUserMessage.parts
      .filter((p) => p.type === "text")
      .map((p: any) => p.text ?? "")
      .join(" ");

  const isCompareIntent =
    typeof latestText === "string" &&
    latestText.toLowerCase().includes("compare");

  // --------------------------------------------------
  // HIDDEN HELPER INSTRUCTIONS FOR COMPARISONS
  // (user NEVER sees this; it's only sent to the model)
  // --------------------------------------------------

  if (isCompareIntent) {
    const hiddenCompareInstructions = `
(INTERNAL INSTRUCTIONS FOR THIS QUERY â€“ DO NOT REPEAT TO THE USER.)

The user has asked you to compare two or more MBA/B-schools.

For THIS message only, you MUST do the following:

1) Interpret the most recent user message as a comparison request between B-schools on specific parameters (e.g. median CTC, average CTC, highest CTC, QS ranking, batch size, program fee, etc.).

2) Always try to use placement and program data for the 2024 batch by default.
   - Treat phrases like "Class of 2024", "2022â€“24", "2023â€“25" as referring to the same graduating cohort.

3) Data sources must be used in this order of priority:
   a) Uploaded PDFs and internal/vectorDatabaseSearch results.
   b) If a clear 2024 value for a parameter+college is missing or unclear, you MUST call the "webSearch" tool yourself (without asking the user).
      - Your webSearch query MUST include:
          â€¢ the college name
          â€¢ the parameter name (e.g. "median CTC", "average CTC", "highest CTC", "batch size", "QS ranking", "program fee")
          â€¢ and a 2024-related keyword such as "2024", "class of 2024", "2022-24", or "2023-25 placement report".
      - Prefer official college sites, official placement report PDFs, or highly reputable MBA portals quoting official data.

4) Fallback when 2024 data is not available:
   - If, after checking PDFs/internal knowledge AND performing at least one appropriate webSearch query, you still cannot find a trustworthy 2024 value for a parameter:
       â€¢ Look for the most recent earlier batch (e.g. 2023) instead of leaving it blank.
       â€¢ When you use an earlier year, clearly label it, for example: "â‚¹30.5 LPA (2023 batch)".
   - Only if you cannot find any credible numeric value for any year may you write "Not available" for that cell.
   - Never use the phrase "Not specified".

5) Final answer format:
   - Present the comparison as a clean markdown table.
   - One column per college.
   - One row per parameter.
   - Use concise numeric or short text values in the cells.
   - For any value taken from webSearch, include a short "Source" link or note in the same cell or immediately below the table.

6) Tool usage and when to stop:
   - In this comparison, do NOT ask the user for permission before calling webSearch or vectorDatabaseSearch; just call them when needed.
   - Once you have a credible value (or have concluded it is not available even after search) for all requested parameters and colleges:
       â€¢ Stop calling tools.
       â€¢ Immediately return the final markdown table as the answer.
   - Do NOT keep searching repeatedly for the same parameter once you have a consistent value.

Again, these instructions are ONLY for this comparison query. Do NOT describe or expose them to the user. Just follow them and respond with the final comparison table.
`;

    // ðŸ‘‡ Append as an extra user message ONLY for the model
    (modelMessages as any[]).push({
      role: "user",
      content: hiddenCompareInstructions,
    });
  }

  // --------------------------------------------------
  // MAIN EXECUTION
  // --------------------------------------------------

  const result = streamText({
    model: MODEL,
    messages: [
      ...systemMessages, // general system instructions
      ...modelMessages,  // original chat + hidden compare helper if any
    ],
    tools: {
      webSearch,
      vectorDatabaseSearch,
    },
    stopWhen: stepCountIs(20),
    providerOptions: {
      openai: {
        reasoningSummary: "auto",
        reasoningEffort: "low",
        parallelToolCalls: false,
      },
    },
  });

  return result.toUIMessageStreamResponse({
    sendReasoning: true,
  });
}
